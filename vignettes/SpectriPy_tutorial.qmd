---
title: "SpectriPy tutorial: Annotation of LC-MS/MS spectra"
bibliography: SpectriPy_tutorial.bib
vignette: >
  %\VignetteIndexEntry{SpectriPy tutorial: Annotation of LC-MS/MS spectra}
  %\VignetteKeywords{Mass Spectrometry, MS, MSMS, Metabolomics, Infrastructure, Quantitative}
  %\VignettePackage{SpectriPy}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{quarto::html}
  %\VignetteDepends{Spectra,BiocStyle,SpectriPy,reticulate,MsBackendMgf,msdata,mzR}
---

**Compiled**: `r date()`

# Introduction

*SpectriPy* enables powerful mass spectrometry (MS) data analysis workflows
combining the strengths of Python and R MS libraries. 
The concepts and examples can be checked by performing some steps from the 
package’s vignette, from source 
https://rformassspectrometry.github.io/SpectriPy/articles/SpectriPy.html.

To showcase the strength
of combining functionalities from both programming languages with *SpectriPy*,
we perform the annotation of LC-MS/MS spectra using a reference library.
During the tutorial, we use different spectral similarity algorithms from both R
and Python: normalized dot product similarity from Spectra
[@rainer_modular_2022], CosineGreedy from matchms [@huber_matchms_2020], 
MS2DeepScore from matchms [@huber_ms2deepscore_2021] and Spec2Vec from spec2vec [@huber_spec2vec_2021].

The spectral reference library used in this tutorial originates from the GNPS
repository (provided in mgf format), which can easily be replaced by the user by
other public spectral databases or with an in-house reference database.
Similarily, the spectral similarity algorithms used in this tutorial, can easily
be extended to other R/python spectral silimilatity algorithms. 


# steps to do = to be removed TODO

Potential example: annotation of LC-MS/MS
+R: Perform LC-MS/MS data preprocessing in R with xcms } part in the metabonaut already
+R: Extract MS2 spectra for features as a Spectra object-    } idem, so maybe refer and load ‘res’ instead? 
-load/make query ==> test/rdata splitup depending vignette/metabonaut? like the mini tesset to horougly explain and show intermed result steps. ok? TODO
+Python: Load reference database, e.g. from a GNPS MGF file
+R: translate Spectra object to Python.
+Python: process and filter the data, both the reference database and the experimental data = filtering
+Python: calculate pairwise similarity (= CosineGreedy from matchms) between the experimental spectra and reference.
-py: others cals...!!! TODO
-spec2vec
    steps before mrd TODO
    + query spectra() -> mgf (or how describe/logical?) ok
    - spec2vec add to spectripy? HOW? jo?
    + codechunks from Marilyn OK
-more COSINEs from matchms?? cross-language-ms-analysis.qmd for other examples. TODO
-py bugs in retic!!!! TODO
+py/r: table with the top1 found names of molec for the query???
-R: translate back to R !!! TODO
+R: plot
-at end (how?), put data in vignette IN package, now via explicit path pc... TODO


# Load SpectriPy

Load required R SpectriPy package.

```{r}
#| warning: false
#' R session:

library(SpectriPy)
```


# Load query MS2 data

for now, select only needed FINDME and describe. TODO: vignette with test, 
metabonaut with load

## Test MS2 data

For this, we first make some test data with 2 MS2 spectra from 2 unknown 
compounds each. In total, we have 4 spectra.

```{r}
#| warning: false
#' R session:

#' R MS package
library(Spectra)

#' Create a Spectra object with two MS2 spectra for unknown compound 1 
#' (== Caffeine).
caf <- DataFrame(
    feature_id = c("FT01", "FT01"),
    msLevel = c(2L, 2L),
    precursorMz = c(195.0877, 195.0877),
    #id = 'HMDB0001847',   
    #name = "Caffeine",
    #smiles = 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',
    #inchi = '1S/C8H10N4O2/c1-10-4-9-6-5(10)7(13)12(3)8(14)11(6)2/h4H,1-3H3',
    parent_mass = 195.08
)
caf$intensity <- list(
    c(340.0, 416, 2580, 412),
    c(388.0, 3270, 85, 54, 10111))
caf$mz <- list(
    c(135.0432, 138.0632, 163.0375, 195.0880),
    c(110.0710, 138.0655, 138.1057, 138.1742, 195.0864))
caf <- Spectra(caf)

#' Create a Spectra object with two MS2 spectra for for unknown compound 2 
#' (== 1-Methylhistidine)
mhd <- DataFrame(
    feature_id = c("FT02", "FT02"),
    msLevel = c(2L, 2L),
    precursorMz = c(170.0924, 170.0924),
    #id = c("HMDB0000001", "HMDB0000001"),
    #name = c("1-Methylhistidine", "1-Methylhistidine"),
    #smiles = 'CN1C=C(N=C1)C[C@@H](C(=O)O)N',
    #inchi = '1S/C7H11N3O2/c1-10-3-5(9-4-10)2-6(8)7(11)12/h3-4,6H,2,8H2,1H3,(H,11,12)/t6-/m0/s1',
    parent_mass = 170.09)
mhd$mz <- list(
    c(109.2, 124.2, 124.5, 170.16, 170.72),
    c(83.1, 96.12, 97.14, 109.14, 124.08, 125.1, 170.16))
mhd$intensity <- list(
    c(3.407, 47.494, 3.094, 100.0, 13.240),
    c(6.685, 4.381, 3.022, 16.708, 100.0, 4.565, 40.643))
mhd <- Spectra(mhd)

#' Create a Spectra object with one MS2 spectra for for unknown compound 3 
#' (== Roxithromycin)
rox <- DataFrame(
    feature_id = "FT03",
    msLevel = 2L,
    precursorMz = 837.5318,
    #name = "Roxithromycin",
    #smiles = 'CC[C@@H]1[C@@]([C@@H]([C@H](/C(=N/OCOCCOC)/[C@@H](C[C@@]([C@@H]([C@H]([C@@H]([C@H](C(=O)O1)C)O[C@H]2C[C@@]([C@H]([C@@H](O2)C)O)(C)OC)C)O[C@H]3[C@@H]([C@H](C[C@H](O3)C)N(C)C)O)(C)O)C)C)O)(C)O',
    #inchi = '1S/C41H76N2O15/c1-15-29-41(10,49)34(45)24(4)31(42-53-21-52-17-16-50-13)22(2)19-39(8,48)36(58-38-32(44)28(43(11)12)18-23(3)54-38)25(5)33(26(6)37(47)56-29)57-30-20-40(9,51-14)35(46)27(7)55-30/h22-30,32-36,38,44-46,48-49H,15-21H2,1-14H3/b42-31+/t22-,23-,24+,25+,26-,27+,28+,29-,30+,32-,33+,34-,35+,36-,38+,39-,40-,41-/m1/s1',
    parent_mass = 170.09)
rox$mz <- list(
    c(116.0712, 116.1074, 127.0759, 142.1231, 158.1184, 159.1218, 380.2469, 398.2568, 679.4443, 680.4436))
rox$intensity <- list(
    c(15660, 28164, 8616, 4516, 855092, 68248, 6148, 8996, 10596, 5176))
rox <- Spectra(rox)


#' Merge the 2 Spectra objects, containing 2 spectra each into 1 search query 
#' Spectra object (== 2 spectra from caf and 2 spectra from 1-methylhis)
ms2_ctr_fts <- c(caf, mhd, rox)
head(ms2_ctr_fts)

#' Print the feature_id of the first spectrum
ms2_ctr_fts$feature_id[1]
```


## Query MS2 data with significant features

The LC-MS/MS query data used in this tutorial, are derived from the Metabonaut 
resource [@louail_metabonaut_2025]. Introduction and a thorough description of the preliminariry 
steps performed are described there, from source
[A Complete End-to-End Workflow for untargeted LC-MS/MS Metabolomics Data Analysis in R](https://rformassspectrometry.github.io/Metabonaut/articles/end-to-end-untargeted-metabolomics.html).

First, we load the MS2 spectra of the unknown features found to be significant 
after the "Differential abundance analysis", see section 
[MS2-based annotation](https://rformassspectrometry.github.io/Metabonaut/articles/end-to-end-untargeted-metabolomics.html#differential-abundance-analysis).

```{r}
#| eval: false
#| warning: false
#' R session:

#' R MS package
library(Spectra)

#' Load the MS2 spectra of significant features
load('/home/mdegraeve/Documents/Files/Work_Eurac/Projects/SpectriPy/spectra_significant_fts.RData') #object is ms2_ctr_fts
head(ms2_ctr_fts)

#' Print the available metadata, stored in the Spectra object
spectraVariables(ms2_ctr_fts)

#' Print the feature_id of the first spectrum
ms2_ctr_fts$feature_id[1]
```


# Filter query data

To ensure this `Spectra` object only contains MS2 data, we filter to only MS2 
spectra with more than 2 fragment peaks per spectrum.

```{r}
#' R session:

#' Filter MS2 level data
ms2_ctr_fts <- filterMsLevel(ms2_ctr_fts, 2L)

#' filter minimum 3 fragment peaks
ms2_ctr_fts <- ms2_ctr_fts[lengths(ms2_ctr_fts) >= 3]
head(ms2_ctr_fts)
```


# Load reference MS2 data

## GNPS spectral library

The MS2 spectral reference library in this tutorial originates
from the GNPS repository, and is provided as an MGF formatted file. 
To load other file formats, see 
[link](https://matchms.readthedocs.io/en/latest/api/matchms.importing.html)

```{python}
#| eval: false
#| warning: false
#'' Python session:

from matchms.importing import load_from_mgf

# Read spectra from an MGF formatted file
mgf_py = list(load_from_mgf("/home/mdegraeve/Documents/Files/Work_Eurac/Projects/SpectriPy/inst/extdata/mgf/pesticides.mgf"))
```


## *In-house* spectral library

We import a test data file in
MGF format using the Python *matchms* library. This MGF file is provided within
the *SpectriPy* package so we first define its file name and path in R. The 
loaded object is a Python's `Spectrum` object.

```{python}
#| warning: false
#' Python session:

from matchms.importing import load_from_mgf

# Read spectra from an MGF formatted file, as Spectrum object
mgf_py = list(load_from_mgf("/home/mdegraeve/Documents/Files/Work_Eurac/Projects/SpectriPy/inst/extdata/mgf/test.mgf"))

#' Nr of spectra
len(mgf_py)

#' Access the first spectrum
mgf_py[0]
```

Note that we can also the first spectrum from an R session, by starting the 
command with `py$`.

```{r}
#' R session:

#' Access the first spectrum
py$mgf_py[[1]]
```


# Translate query from R Spectra to py Spectrum

## Conversion of MS2 data to Spectrum object

First, we check if the r Spectra object containing the query MS2 data can be 
accessed in python using the 'r.' prefix.

```{python}
#' Python session:

# check if the r Spectra object can be accessed in python using the 'r.' 
# prefix
r.ms2_ctr_fts
```

Second, we translate the Spectra 
object 'ms2_ctr_fts' to the py Spectrum object 'ms2_ctr_fts_py'.

```{r}
#' R session:

#' Add mapping for additional spectra variables to the default mapping in R and
#' python, respectively
map = c(defaultSpectraVariableMapping(), 
        feature_id = 'feature_id')

#' Convert to py Spectrum
#' pass via 'mapping' the "r = 'py'" translation
system.time(
    ms2_ctr_fts_py <- rspec_to_pyspec(ms2_ctr_fts, mapping = map) 
)
ms2_ctr_fts_py
```

Third, we check if the R convertend Spectrum object can be accessed in python 
using the 'r.' prefix.

```{python}
#' Python session:

# check if the "r convertend Spectrum" object can be accessed in python using 
# the 'r.' prefix
r.ms2_ctr_fts_py
```


# Filter py Spectrum reference library

Before we run the spectral comparisons of our query data to the MGF reference
library, we apply some filtering from matchms. Default filtering was performed 
to standardize ion mode, correct charge and more. See the 
[matchms filtering documentation](https://matchms.readthedocs.io/en/latest/api/matchms.filtering.html).

```{python}
#| warning: false
#' Python session:

from matchms.filtering import default_filters, normalize_intensities

# Apply filters to clean and enhance each spectrum
clean_mgf_py = []
for spectrum in mgf_py:
    # Apply default filter to standardize ion mode, correct charge and more.
    # Default filter is fully explained at https://matchms.readthedocs.io/en/latest/api/matchms.filtering.html
    spectrum = default_filters(spectrum)
    # Scale peak intensities to maximum of 1
    spectrum = normalize_intensities(spectrum)
    clean_mgf_py.append(spectrum)

#' Nr of spectra
len(clean_mgf_py)
```


# Evaluation of different spectral similarity algorithms

We calculate the pairwise similarity between the query spectra and the
reference library spectra using different approaches, using spectral 
objects (Spectra, Spectrum) accross both languages and using algoritms from
multiple libraries.


## CosineGreedy from matchms

next, we calculate the pairwise similarity between the query spectra and the
reference library spectra using Python's matchms.

Here, we use the spectral similarity algorithm CosineGreedy from matchms, from 
source [matchms](https://github.com/matchms/matchms/blob/master/README.rst).  
This algorithm can easily be exchanged for another spectral similarity 
calculation from matchms. See 
[here](https://matchms.readthedocs.io/en/latest/api/matchms.similarity.html) 
for other similarity score methods.

```{python}
#' Python session:

from matchms import calculate_scores
from matchms.similarity import CosineGreedy

# Calculate Cosine similarity scores between all spectra
# For other similarity score methods see https://matchms.readthedocs.io/en/latest/api/matchms.similarity.html
similarity_score = CosineGreedy(tolerance = 0.1)  # Change this for other algorithm
scores = calculate_scores(references = clean_mgf_py,
                          queries = r.ms2_ctr_fts_py,
                          similarity_function = similarity_score)
scores
```


### Evaluation

From the calculated spectral similarity scores, we rearange the data to 
make a dataframe containing the best matched compound name (derived from the 
reference library) per queried spectrum.

First, we extract and transpose the scores as a python array. Each row of the 
array will contain the similarity scores of one spectrum from our query spectra 
`r.ms2_ctr_fts_py` against the cleaned reference library `clean_mgf_py`. 

```{python}
#' Python session:

# Convert to array and transpose
sim_matchms = scores.to_array()["CosineGreedy_score"]
sim_matchms = sim_matchms.T

# Contains 1 row for each spectrum in query 
sim_matchms.shape
```

Next, we create a dataframe with per queried spectrum from our unknown 
variables, the compound name of the higest matching spectra from the reference 
library and the corresponding similarity score.

```{python}
#' Python session:

# not correct when run through reticulate... TODO FINDEME!!!! sure correct code!!!!!!

import numpy as np
import pandas as pd

# Prepare results list
results = []
for i in range(sim_matchms.shape[0]):

    #row is the query, keep nr in the results instead of replacing by eg id
    name_row = r.ms2_ctr_fts_py[i].get('feature_id') 
    
    row_values = sim_matchms[i].copy()
    
    # match with higest col nr from the references
    max_col = np.argmax(row_values)  # Find column index of max value
    max_value = row_values[max_col]  # Get max value

    # replace the nr of refererences with the name
    name_max_col = clean_mgf_py[max_col].get('compound_name') 

    results.append({"query": i + 1, #count from 1
                    "query_feature_id": name_row, 
                    "reference": max_col,
                    "reference_compound_name": name_max_col, 
                    "CosineGreedy_score": max_value})

# Convert to DataFrame
df = pd.DataFrame(results)

# Print the full DataFrame
df
```

[!] **Caution**: 
As the higest score is taken as criteria for the annotation, a lot of 
caution is needed evaluation the trueness of the match. A low score is not 
reliable, as the similarity algorithm will calculate a score for each pairwise 
pair. Therefore, a match will alsways be found. In addition, if you unknown 
compound is absent in the reference library, it will match wrongly to another 
compound that is present in the database.

To ensure blindly using the above dataframe, we apply a filter of 0.7 below the 
MS2 spectral matching is deemed unrealiable. Above this value, the potential 
annotations need to be validated using e.g. rerunning samples in the presence of
commercial standards. 

```{python}
#' Python session:

# Keep only rows where score > 0.7
df_filtered = df[df["CosineGreedy_score"] > 0.7]

# Print the filtered DataFrame
df_filtered
```

Regarding our first unknown feature FT01, which are actually 2 MS2 spectra from 
caffeine, we see that the higest match of the 1st and 2nd spectra are both 
matched correctly (Cosine Greedy scores 1.00 and 0.99) to the spectra of 
caffeine in the in-house spectral library.

In the case of our second unknown feature FT02, no trustworthy matches were 
made. This spectra is was actually derived from 1-Methylhistidine, which is not 
present in the in-house spectral library. Therefore, no matches should be found.

To visually inspect how well the query qnd reference spectra match, we refer to 
the [Metabonaut resource](https://rformassspectrometry.github.io/Metabonaut/articles/end-to-end-untargeted-metabolomics.html) on how to generate the mirror plots.


## Dot product from Spectra

Here, we calculate the pairwise similarity between the query spectra and the
reference library spectra using R's Spectra.

In R we can use the `compareSpectra()` function that by default calculates the
normalized dot product similarity between the compared spectra. The MS data from
the mzML file was processed in Python. To use this data we first create a
`Spectra` object with a `MsBackendPy` backend. See the 
[SpectriPy vignette](https://rformassspectrometry.github.io/SpectriPy/articles/SpectriPy.html) 
for more information regarding calculation performance and (memory) efficiency.

```{r}
#' R session:

#' R MS package
library(Spectra)

#' Create a Spectra object with a MsBackendPy backend for the
#' attribute "clean_mgf_py"
clean_mgf_r <- Spectra("clean_mgf_py", source = MsBackendPy())

#' Calculate the pairwise similarity between spectra
sim_spectra <- compareSpectra(clean_mgf_r, #reference
                              ms2_ctr_fts,  #query
                              tolerance = 0.1)

#' Transpose to add to results table
sim_spectra <- t(sim_spectra)
dim(sim_spectra)
```


### Evaluation

To evaluate, we rearange and filter the MS2 spectral similarity matrix as in the 
previous section, only using R this time.

```{r}
#' R session:

# Initialize results dataframe
results <- data.frame(query = numeric(), query_feature_id = character(), 
                      reference = numeric(), 
                      reference_compound_name = character(), 
                      dot_score = numeric(), stringsAsFactors = FALSE)

# Loop over rows to find highest value
for (i in 1:nrow(sim_spectra)) {
  row_values <- sim_spectra[i, ]
  
  #row is the query, keep nr in the results instead of replacing by eg id
  name_row = ms2_ctr_fts$feature_id[i]

  max_col <- which.max(row_values)  # Find column index of max value, ! r counts from 1
  max_value <- row_values[max_col]  # Extract max value
  
  # replce the nr of refererences with the name
  name_max_col = clean_mgf_r$compound_name[max_col] #check count in R from 1

  results <- rbind(results, data.frame(query = i, 
                                       query_feature_id = name_row,
                                       reference =  max_col,
                                       reference_compound_name = name_max_col, 
                                       score = max_value))
}

# Keep only ows where score > 0.7
results <- results[results$score > 0.7, ]

# Print the results
print(results)
```

The same results, with small deviation score values, are found for the test 
data with 2 unknown features.


## MS2DeepScore from matchms

Here, we calculate the pairwise similarity between the query spectra and the
reference library spectra using R's Spectra. FINDME!!! TODO

X NOT: Tanimoto score IS WITH SMILES... or other fingerprint, so if unknown spectra, how do they have a smiles...?? think in this goal not useful 

steps before mrd
- query spectra() -> mgf (or how describe/logical?)
- ok with torch, msdeepscore add to spectripy? HOW? jo?
- codechunks from Matthias OK

```{r}



```


### Evaluation


## Spec2Vec from spec2vec

Here, we calculate the pairwise similarity between the query spectra and the
reference library spectra using Pythons's spec2vec. 

We also apply a stricter filtering processing from matchms. Thhis will be 
performed on both the reference and query spectra, and for this 
reason we will have a shorter results table. 

```{python}
#| warning: false
#' Python session:

import os
import matchms.filtering as msfilters
from spec2vec import SpectrumDocument
from spec2vec.model_building import train_new_word2vec_model

def spectrum_processing(s):
    """This is how one would typically design a desired pre- and post-
    processing pipeline."""
    s = msfilters.default_filters(s)
    s = msfilters.add_parent_mass(s)
    s = msfilters.normalize_intensities(s)
    s = msfilters.reduce_to_number_of_peaks(s, n_required = 10, 
                                               ratio_desired = 0.5, 
                                               n_max = 500)
    s = msfilters.select_by_mz(s, mz_from = 0, mz_to = 1000)
    s = msfilters.require_minimum_number_of_peaks(s, n_required = 10)
    return s

# Apply filters to the Spectrum of refernce
reference_spectrums = [spectrum_processing(s) for s in clean_mgf_py]

# Omit reference_spectrums that didn't qualify for analysis
reference_spectrums = [s for s in reference_spectrums if s is not None]
```

First, we train a new spec2vec model using our MS2 spectral reference library 
after processing thereof.

```{python}
# Create spectrum documents
reference_documents = [SpectrumDocument(s, n_decimals=2) for s in reference_spectrums]

model_file = "references.model"
model = train_new_word2vec_model(reference_documents, iterations = [10, 20, 30], 
                                 filename = model_file,
                                 workers=2, progress_logger=True)
```

load the query data, filter the spectra and find spectral similarities using 
the trained spec2vec model.

```{python}
#' Python session:

import gensim
from matchms import calculate_scores
from spec2vec import Spec2Vec

# query_spectrums
query_spectrums = [spectrum_processing(s) for s in r.ms2_ctr_fts_py]

# Omit spectrums that didn't qualify for analysis
query_spectrums = [s for s in query_spectrums if s is not None]

# Import pre-trained word2vec model (see code example above)
model_file = "references.model"
model = gensim.models.Word2Vec.load(model_file)

# Define similarity_function
spec2vec_similarity = Spec2Vec(model = model,
                               intensity_weighting_power = 0.5, #Default 0.5
                               allowed_missing_percentage = 5.0)  #Default 5.0

# Calculate scores on all combinations of reference spectrums and queries
scores = calculate_scores(reference_documents, query_spectrums, spec2vec_similarity)

scores
```

from the scores object, we can repeat exactly the part of matchms to get to 
the matches for out unknown query MS2 spectra.


### Evaluation

From the calculated spectral similarity scores, we rearange the data to 
make a dataframe containing the best matched compound name (derived from the 
reference library) per queried spectrum.

First, we extract and transpose the scores as a python array. Each row of the 
array will contain the similarity scores of one spectrum from our query spectra 
`r.ms2_ctr_fts_py` against the cleaned reference library `clean_mgf_py`. 

```{python}
#' Python session:

# Convert to array and transpose
sim_spec2vec = scores.to_array()
sim_spec2vec = sim_spec2vec.T

# Contains 1 row for each spectrum in query 
sim_spec2vec.shape
```

Next, we create a dataframe with per queried spectrum from our unknown 
variables, the compound name of the higest matching spectra from the reference 
library and the corresponding similarity score.

Because the processing of the query and reference spectra, less than 4 and 100
spectra, respectively, are left. Therefore, we use the filtered python's 
Spectrum objects `r.ms2_ctr_fts_py` -> `query_spectrums` and `clean_mgf_py` 
-> `reference_spectrums` in the next code chunk.

```{python}
#' Python session:

import numpy as np
import pandas as pd

# Prepare results list
results = []
for i in range(sim_spec2vec.shape[0]):

    #row is the query, keep nr in the results instead of replacing by eg id
    name_row = query_spectrums[i].get('feature_id')
    
    row_values = sim_spec2vec[i].copy()
    
    # match with higest col nr from the references
    max_col = np.argmax(row_values)  # Find column index of max value
    max_value = row_values[max_col]  # Get max value

    # replace the nr of refererences with the name
    name_max_col = reference_spectrums[max_col].get('compound_name') 

    results.append({"query": i + 1, #count from 1
                    "query_feature_id": name_row, 
                    "reference": max_col,
                    "reference_compound_name": name_max_col, 
                    "Spec2Vec_score": max_value})

# Convert to DataFrame
df = pd.DataFrame(results)
```

The result list contains less of the query and library spectra. After findering
this table with a score > 0.7 we get:

```{python}
# Keep only rows where score > 0.7
df_filtered = df[df["Spec2Vec_score"] > 0.7]

# Print the filtered DataFrame
df_filtered
```

The results from spec2vec are much stricter, due to the strict filtering prior 
to the spectral similarity calculation. The perfect matching caffeine in the 
first spectra of the query test data was omited now.


# Compare different similarity scores

To conclude, we want to see how much the spectral similarity scores differ 
between the different algoritms preformed above. The score matrix from matchms
is stored in the Python object `sim_matchms` and the score matrix from spectra
in R's `sim_spectra`.

```{r}
#' R session:

#' Plot the similarity scores against each other
plot(py$sim_matchms, sim_spectra, pch = 21, col = "#000000ce", bg = "#00000060",
     xlab = "Cosine Greedy", ylab = "Dot product")
grid()

```

TODO change so now we have 4 comps... maybe a heatmap with 1st spectrum (caffeine)
and the scores of each??


# Adding annotated spectra to R

After thorough inspection, we decide that we want to add the putative 
annotation of the first feature to our test data. We add this information in 
the originally made R Spectra object. As both object are loaded twice, both an
R Spectra object `ms2_ctr_fts` and a Python Spectrum object `r.ms2_ctr_fts_py`, 
this new info will only be added in the original Spectra object.

```{r}
#' R session:

#' Print the feature_id of the first spectrum
#ms2_ctr_fts$name[1] <- "Caffeine" #FINDME, how to add?? idea is for user to stay in r, eg mirror plot with name on top or so....

#spectraVariables(ms2_ctr_fts)

    #id = 'HMDB0001847',   
    #name = "Caffeine",
    #smiles = 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',
    #inchi = '1S/C8H10N4O2/c1-10-4-9-6-5(10)7(13)12(3)8(14)11(6)2/h4H,1-3H3',

```


# Session information

```{r}
#' R session:

sessionInfo()
```


# References
